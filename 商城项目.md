1.项目创建

对每个服务分别创建模块，最后聚合在一个整体模块中

![image-20220205232041432](E:\File\Study\Note\picture\商城项目\image-20220205232041432.png)

父项目`pom.xml`文件

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>cn.xf</groupId>
    <artifactId>MallPro</artifactId>
    <version>1.0-SNAPSHOT</version>
    <packaging>pom</packaging>
    <description>商城项目聚合服务</description>
    <name>MallPro</name>

    <modules>
        <module>coupon</module>
        <module>member</module>
        <module>order</module>
        <module>product</module>
        <module>warehousing</module>
        <module>common</module>
        <module>renren-fast</module>
        <module>renren-generator</module>
    </modules>
</project>
```

2.数据库初始化

`电商项目不要使用外键，当数据量过大时，要对每条数据进行外键检查，耗费资源`



3.项目逆向工程

使用人人开源代码生成对项目进行生成



4.整合mybatispluse

导入依赖

```
<dependency>
	<groupId>com.baomidou</groupId>
	<artifactId>mybatis-plus-boot-start</artifactId>
	<version></version>
</dependency>
```

配置数据源

```
// 导入数据库驱动
<dependency>
    <groupId>mysql</groupId>
	<artifactId>mysql-commector-java</artifactId>
	<version></version>
</dependency>

// 配置数据源（.yml）
spring:
	datasource:
		username: 
		password:
		url: jdbc:mysql:///
		driver-class-name: com.mysql.jdbc.Driver
```

配置myabtis-Pluse

```
使用MapperScan扫描Mapper接口
@MapperScan("。。。。dao")
// 告诉mybatis-plus映射文件在哪里
mybatis-plus:
	mapper-locations: classpath*:/
// 主键自增
	global-config:
		db-config:
			id-type: auto 
```

5.其他jar

`servlet`



6.微服务搭建

微服务：注册中心（Nacos），配置中心（Nacos），负载均衡（Ribbon），服务容错（Sentinel），api网关（Gateway），声明式Http客户端（Feign）

1) spring.cloud.nacos.discovery.server-addr=127.0.0.1:8847

```
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
	<version></version>
</dependency>
```

2. 配置文件中配置 Nacos Server 地址

```
 spring.cloud.nacos.discovery.server-addr=127.0.0.1:8847
```

3. 使用 @EnableDiscoveryClient 注解开启服务注册与发现功能
4. 在每个服务中设置对相应的名字`spring.application.name: `

`完成上述步骤后，从127.0.0.1:8847/nacos中就能将该服务注册到nacos中`

nacos启动后不是本机ip地址问题

`修改config/application.properties文件，指定IP地址启动nacos.inetutils.ip-address=127.0.0.1`

## Nacos作为注册中心

**openFeign远程调用**

feign是一个**声明式**的HTTP客户端，让远程调用更加简单，Feign提供了HTTP请求的模板，**通过编写简单的接口和插入注解**，就能定义HTTP请求参数、格式、地址等。Feign整合了Ribbon（负载均衡）和Hystrix（服务熔断），让我们不再显示使用这两个组件。

1. 使用

引入依赖：

```
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
    <version></version>
</dependency>
```

编写接口，让springCloud明白需要调用远程服务

```
/**
* 这是一个远程声明式接口
*/
@FeignClient("远程服务名")
public interface FeignService{
	// 声明接口中的方法调用那个服务的那个请求
	@RequestMapping("/请求方法")
	public void method();
}
```

在启动类中使用`@EnableFeignClients(basePackages="feign所在的目录")`开启远程调用功能



2. 问题

   启动nacos后，服务启动异常`com.alibaba.nacos.api.exception.NacosException: Request nacos server failed:`

   A：将nacos启动项中启动模式改为`set MODE="standalone"`

   启动服务`No Feign Client for loadBalancing defined. Did you forget to include spring-cloud-starter-loadbalancer`

   A：需要引入jar包

   ```
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-loadbalancer</artifactId>
       <version>3.1.0</version>
   </dependency>
   ```

3. 引入spring-cloud-stater-loadbalacer后nacos中的ribbon造成loadbalancer失效

   A：

   ```
    <dependency>
        <groupId>com.alibaba.cloud</groupId>
        	<artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
        <exclusions>
            <exclusion>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>
            </exclusion>
        </exclusions>
    </dependency>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-loadbalancer</artifactId>
        <version>2.2.2.RELEASE</version>
    </dependency>
   
   ```



## Nacos作为配置中心

将配置交给配置中心(本地使用bootstrap.properties文件)

1.引入依赖

```
 <dependency>
     <groupId>com.alibaba.cloud</groupId>
     <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
     <version></version>
 </dependency>
```

2.在bootstrap.properties中配置Nacos config元数据

`bootstrap.properties会高于application.properties进行加载`

```properties
 # 命名空间名字
 spring.application.name=nacos-config-example 
 spring.cloud.nacos.config.server-addr=127.0.0.1:8847
```

3.获取动态配置信息

```
@RefreshScope：添加在controller中，动态获取并刷新配置
@Value("${配置项的名}")：获取到配置
```

`如果配置中心和当前应用的配置文件又相同配置，优先使用配置中心配置`

4.在nacos配置中心中添加配置信息：

```
dataId is serviceName.properties
group is DEFAULT_GROUP
```





**命名空间与配置集**

命名空间：做配置隔离（可用来区分开发环境）

​	默认为public（保留空间），默认新增的所有配置都在public空间

​	1、开发，测试，生产，利用命名空间做环境隔离

​		在bootstrap.properties：配置中，需要使用那个命名空间的配置为：

​		`spring.cloud.nacos.config.namespace=nacos配置列表中每个环境的id`

​	2、基于每个微服务之间相互隔离，每个微服务使用自己的命名空间，只加载自己的命名空间下的配置



配置集：

​	一个配置文件中所有配置的集合



配置集ID：

​	类似于配置文件名字

​	在nacos中为配置的Data ID



配置分组：

​	nacos中的GROUP；默认的配置集都属于DEFAULT_GROUP

​	`指定使用分组配置文件：spring.cloud.nacos.config.group=`



使用多个命名空间

-- 第n个

`spring.cloud.nacos.config.ext-config[第n个].data-id=配置文件名字`

`spring.cloud.nacos.config.ex-config[第n个].group=选择那个组`

`spring.cloud.nacos.config.ext-config[第n个].refresh =是否动态刷新`



使用微服务开发时，可将所有配置放在nacos中，本地只保留bootstrap.properties文件即可



## 网关（Gateway）

作为流量的入口，常用来转发，权限校验，限流控制等

1.添加模块，引入依赖

```
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-gateway</artifactId>
</dependency>

// 依赖公共模块
...
```

2.开启服务注册发现

`@EnableDiscoveryClient`

配置nacos注册中心地址

```
# nacos元数据
spring.application.name=gateway
spring.cloud.nacos.config.server-addr=127.0.0.1:8847

spring.cloud.nacos.config.namespace=da5337fb-2cbe-474d-8425-485f157a9fc9


# 加载nacos中其他数据集
spring.cloud.nacos.config.extension-configs[0].data-id=application.yml
spring.cloud.nacos.config.extension-configs[0].group=dev
spring.cloud.nacos.config.extension-configs[0].refresh=true
```







## 前端

**ES6**

ECMAScript6.0，是javaScript语言的下一代标准。ECMAScript是浏览器脚本语言的规范，js则是规范的具体实现 

```
let与var

let又严格作用域，不能多次申明变量
var会越域，可多次申明变量

const申明的是只读常量，不可修改
```

箭头函数

```
// 以前申明方法
var print=function(obj){
	console.log(obj);
}
// 箭头
var print = obj => console.log(obj);
var print2 = (a,b) => console.log(a+b);
```

对象优化

```
// 获取对象的键值对
Object,keys(obj)
Object,values(obj)
// 将对象转为数组
Object,entries(obj)

// 对象合并
Object.assign(目标对象，需要赋值的对象...)

// 声明对象简写
const name=xx
const age=12
const person={name:name,age:age}
// 当属性与申明变量一致时
const persion={name,age}

// 对象函数属性简写
let person = {
	name:'xxx',
	eat:function(food){
		console.log(this.name+'吃'+food)
	},
	// 箭头函数中this使用无效，需要用'对象.属性'获取数据
	sport:play=>console.log(person.name+"在玩"+play)
}

//对象扩展运算符
// 拷贝对象
let person = {name:'xxx',age:31}
let otherperson = {...person}
// 合并对象
let age = 23
let name = 'fff'
let person={...age, ...name}

```

map与reduce

```
map();接收一个函数，将原数组中的所有元素用这个函数处理后放入新数组返回
reduce();为数组中的每一个元素执行回调函数，不过阔数组中被删除或从未被赋值的元素
```



**Vue**

```
MVVM思想：
M:model，包括数据和一些基本操作
V:View，视图，页面渲染结果
VM:View-Model，模型与视图间的双向操作，
```

安装（vue的模块化开发）

```
1.全局安装webpack
npm install webpack -g

2.全局安装vue脚手架
npm install -g @vue/cli-init

3.初始化vue项目（使用vue初始化一个appname项目）
vue init webpakc appname
```

整合elementui

```
1.安装elementui
npm i element-ui

2.main.js中导入elementui
// 导入elementui
import elementui from 'element-ui'
// 导入elementui样式文件
import 'element-ui/lib/theme-chalk/index.css'
// 使用elementui
Vue.use(elementui)
```

## 商品服务三级分类
后端编写完后，将数据展示在前端页面

前端修改请求不同的端口服务时：

修改static/config/index.js文件，将所有请求交给网关处理

--------------start-------------------

配置完成后导致验证码请求错误：
```
   将renren-fast中注册common模块
   对配置文件添加springname与cloud:nacos:discovery:server-addr:
   为启动项添加@EnableDiscoveryClient
   
   为当前请求添加路由到网关
   gateway:
      routes:
          - id: admin_route
            uri: lb://renren-fast
            #配置断言，什么路径下触发
            predicates:
              - Path=/api/**
   
   这是请求发现路径不正确，需要对请求路径过滤重写
   filters:
      - RewritePath=/api/(?<segment>.*),/renren-fast/$\{segment}
```
验证码解决后登录错误(跨域问题)：

出现：
```
浏览器对javascript施加的安全措施
同源策略：指协议，域名，端口都要相同，一个不同就会产生跨域
```
跨域流程：
```
https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS
非简单请求（PUT，DELETE）等，
浏览器会先发送预检请求OPTIONS到服务器
服务器相应允许跨域到浏览器
浏览器发送真实请求到服务器
服务器响应数据到浏览器
```
解决理论：
```
一、使用nginx部署为同一域
二、配置档次请求允许跨域
添加响应头：
   Access-Control-Allow-Origin：支持那些来源请求
   Access-Control-Allow-Method：支持哪些方法跨域
   Access-Control-Allow-Credentials：跨域请求默认不包含cookie，设置为true可含cookie
   Access-Control-Expose-Headers：跨域请求暴露字段
      CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Contro、
      Content-Language、Content-type、Expires、Last-Modified、Pragma。如果要拿其他字段，需要
      在Access-control-Expose-Header中指定
   Access-Control-Max-Age：表明该响应的有限时间为多少秒，在有效时间内，浏览器无需为同意请求再次发起
   预检请求。浏览器自身维护了一个最大的有效时间，如果该字段值超过最大有效时间，将不会生效
```
解决：网关中配置跨域
```java
@Configuration
public class CorsConfig {
    @Bean
    public CorsWebFilter corsWebFilter() {

        /*CorsConfigurationSource configurationSource = new CorsConfigurationSource() {
            @Override
            @Override
            public CorsConfiguration getCorsConfiguration(ServerWebExchange exchange) {
                return null;
            }
        };*/
        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
        CorsConfiguration configuration = new CorsConfiguration();

        //配置跨域
        configuration.addAllowedHeader("*");
        configuration.addAllowedMethod("*");
        configuration.addAllowedOriginPattern("*");
        configuration.setAllowCredentials(true);

        source.registerCorsConfiguration("/**",configuration);

        // 需要传入跨域的配置信息
        return new CorsWebFilter(source);
    }
}

// 可能需要注掉renren-fast的同源策略：io.renren.config.CorsConfig
```
------------end----------------

解决完跨域后，为商品类型菜单添加路由到网关中,并为商品服务添加注册中心与配置中心
```yaml
# 为网关添加路由(精确的路由优先级更高)
- id: product_route
      uri: lb://product
      #配置断言，什么路径下触发
      predicates:
        - Path=/api/product/**
      filters:
        # 将api下的所有请求，将api去掉剩下的为请求路径
        - RewritePath=/api/(?<segment>.*),/$\{segment}

# 完整配置文件
server:
   port: 88

spring:
   application:
      name: gateway
   cloud:
      nacos:
         discovery:
            server-addr: 127.0.0.1:8847
      gateway:
         routes:
            - id: product_route
              uri: lb://product
               #配置断言，指定路径下触发
              predicates:
                 - Path=/api/product/**
               # 将api下的所有请求，将api去掉剩下的为请求路径
              filters:
                 - RewritePath=/api/?(?<segment>.*), /$\{segment}
            - id: admin_route
              uri: lb://renren-fast
               #配置断言，指定路径下触发
              predicates:
                 - Path=/api/**
               # 将api下的所有请求，将api去掉剩下的为请求路径
              filters:
                 - RewritePath=/api/?(?<segment>.*), /renren-fast/$\{segment}

# 为商品服务添加注册中心
application:
    name: product
  # 注册中心
  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8847
```
```properties
# 商品服务配置中心
# nacos元数据
spring.application.name=product
spring.cloud.nacos.config.server-addr=127.0.0.1:8847

# nacos命名空间id
spring.cloud.nacos.config.namespace=eb41d029-6c65-47df-9cdb-a17752e6d6ab

# 加载nacos中其他数据集
spring.cloud.nacos.config.extension-configs[0].data-id=application.yml
spring.cloud.nacos.config.extension-configs[0].group=dev
spring.cloud.nacos.config.extension-configs[0].refresh=true
```
对商品类型进行CURD操作：

删除：逻辑删除(mybatis-plus)
```yaml
# 1.配置全局删除规则（可省略）
mybatis-plus:
  global-config:
    db-config:
      logic-delete-value: 1 # 逻辑已删除值(默认为 1)
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)

# 2.配置逻辑删除组件（可省略）
# 3.实体类加上逻辑删除注解
@TableLogic
# 或自定义规则，value
@TableLogic(value="",delval="")
```

对商品添加可拖拽功能

1、对树开启可拖拽功能与方法
```
draggable
:allow-drop="allowDrop"
```

2、拖拽方法实现（保持现有最大层级关系--不能拖拽成为大于当前最大节点的节点）
```javascript
allowDrop(draggingNode, dropNode, type) {
      console.log(draggingNode, dropNode, type)
      // 拖拽结果不能大于三级层级
      // 被拖动节点的层级数
      this.countNodeLevel(draggingNode.data)
      // 当前节点与父节点深度相加<=3即可
      let currentLevel = this.maxLevel - draggingNode.data.catLevel + 1
      console.log(currentLevel)
      if (type == 'inner') {
        return (currentLevel + dropNode.level) <= 3
      } else {
        return (currentLevel + dropNode.parent.level) <= 3
      }
    },
    countNodeLevel(node) {
      console.log(node)
      // 找到所有子节点，求出最大深度
      if (node.childrenList !== null && node.childrenList.length > 0) {
        let children = node.childrenList
        for (let i = 0; i < children.length; i++) {
          if (children[i].catLevel > this.maxLevel) {
            this.maxLevel = children[i].catLevel
          }
          this.countNodeLevel(children[i])
        }
      }
    }
```

3、完善拖拽功能--拖拽保存
```
1.对树添加拖拽成功完成时触发事件
@node-drop="handleDrop"
共有四个参数：被拖拽节点Node，结束拖拽是进入的节点、被拖拽节点放置位置、event
2.handleDrop Function
handleDrop(draggingNode, dropNode, type, event) {
      console.log(draggingNode, dropNode, type)
      // 父节点id
      let parentId = 0
      // 重新排序的列表
      let reSortList = null;
      //1.当前节点最新的父节点
      if (type === 'before' || type === 'after') {
        // 获取当前节点现在所在位置的父id--根据当前所在位置的兄弟节点获取--如果推拽到了一级节点，一级父级分类id会出现undefined
        parentId = dropNode.parent.data.catId === undefined ? 0 : dropNode.parent.data.catId
        reSortList = dropNode.parent.childNodes
      } else {
        // 如果拖拽方式是inner，则获取当前所在节点的id
        parentId = dropNode.data.catId
        reSortList = dropNode.childNodes
      }
      //2.当前拖拽节点最新的排序（从当前父级下可获取到）
      for (let i = 0; i < reSortList.length; i++) {
        // 如果是当前拖拽的节点--修改顺序和父Id
        if (reSortList[i].data.catId === draggingNode.data.catId) {
          //3.当前拖拽节点最新层级
          // 如果层级发生变化--当前拖动的节点与正在遍历的节点的层级不一致
          let catLevel = draggingNode.data.catLevel
          if (reSortList[i].level != draggingNode.level) {
            // 当前节点层级变化修改
            catLevel = reSortList[i].level
            // 子节点层级变化
            this.updateChildNode(reSortList[i]);
          }
          this.tempChange.push({catId: reSortList[i].data.catId, sort: i, parentCid: parentId, catLevel: catLevel});
        } else {
          this.tempChange.push({catId: reSortList[i].data.catId, sort: i})
        }
      }
      console.log(this.tempChange)
      // 保存拖拽后层级关系
      this.$http({
        url: this.$http.adornUrl("/product/category/reSort"),
        method: 'post',
        data: this.$http.adornData(this.tempChange, false)
      }).then(({data}) => {
        this.$message({
          message: "菜单顺序等修改成功",
          type: "success"
        });
        //刷新出新的菜单
        this.getDataList();
        //设置需要默认展开的菜单
        this.expandKye = [parentId];
        // 清空到默认值
        this.tempChange = [];
        this.maxLevel = 0;
      });
    },
    // 递归子节点，修改层级
    updateChildNode(node) {
      if (node.childNodes.length > 0) {
        for (let i = 0; i < node.childNodes.length; i++) {
          // 当前数据
          var cNode = node.childNodes[i].data;
          this.tempChange.push({
            catId: cNode.catId,
            catLevel: node.childNodes[i].level
          });
          this.updateChildNode(node.childNodes[i]);
        }
      }
    },
```
4、防止拖拽误操作、批量保存（拖动完成后再保存）、批量删除功能

品牌管理CRUD

文件上传：
```
1、普通上传（单体应用）
浏览器-->商品服务

2、分布式
                     |---->自建服务器（成本高，搭建复杂，维护成本高），fastDFS，vstfpd
浏览器-->商品服务-->文件存储
                     |---->云存储
```

```
原生sdk
1、添加jdk

2、开通子账号

3、使用阿里云开发文档测试上传 三方存储

springcloudalibaba
1、jdk
<dependency>
   <groupId>com.alibaba.cloud</groupId>
   <artifactId>spring-cloud-starter-alicloud-oss</artifactId>
   <version>2.2.0.RELEASE</version>
</dependency>
2、添加配置
spring.cloud.alicloud.access-key:
spring.cloud.alicloud.secret-key:
spring.cloud.alicloud.oss.endpoint:
3、调用
注入OSSClient
```
阿里对象存储，服务端签名后直传

1.创建third-party模块用来管理三方服务
2.添加依赖jdk（公共配置-忽略mybatis，阿里对象管理）
3.本地添加.properties文件
4.在nacos中添加配置文件
```yaml
server:
    port: 30000
spring:
    application:
        name: thirdParty
    cloud:
        nacos:
            discovery:
                server-addr: 127.0.0.1:8847
        alicloud:
            access-key: xxxx
            secret-key: xxxx
            oss:
                endpoint: https://oss-cn-chengdu.aliyuncs.com
```
5.启动后出现`Consider defining a bean of type 'com.aliyun.oss.OSSClient' in your configuration.`
注入是应该使用接口OSS，而不是实现类OSSClient
6.将请求路径配置到gateway中

7.前端调用方法时出现跨域
为OSS添加跨域访问设置

做添加功能时，使用JSR303进行双向验证（及前后端都做校验），防止添加时绕过前端校验

1.添加校验jar
```pom
<!-- Bean校验 -->
<dependency>---不生效
   <groupId>javax.validation</groupId>
   <artifactId>validation-api</artifactId>
   <version>2.0.1.Final</version>
</dependency>

<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-validation</artifactId>
   <version>2.3.5.RELEASE</version>
</dependency>
```
2.在方法中对那个类进行校验添加@Valid，校验错误后会有默认响应

3.可以紧跟给校验的bean一个BindingResult，可以得到校验结果
```
if (result.hasErrors()) {
   Map<String, String> map = new HashMap<>();
   // 获取校验错误结果
   result.getFieldErrors().forEach((item) -> {
       String message = item.getDefaultMessage();
       // 错误属性名
       String field = item.getField();
       map.put(field, message);
   });
}
```
4.分组校验（对不同操作中不同校验进行分组），
`在校验注解中标注什么情况进行校验groups={interface.class...}，然后在指定方法中添加@Validated({interface.class})`
使用了分组校验，就必须对需要检验的字段都增加分组，否则未指定分组的校验不生效

5.自定义校验
```
1.编写自定义校验注解
2.编写自定以校验器
3.关联校验器与注解
```
校验注解
```java
@Documented
@Constraint(validatedBy = {ListValueConstraintValidator.class})
@Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE})
@Retention(RUNTIME)
public @interface ListValue {

    String message() default "{cn.xf.common.validate.ListValue.message}";

    Class<?>[] groups() default {};

    Class<? extends Payload>[] payload() default {};

    // 校验注解
    int[] value() default {};

}
```
校验器
```java
public class ListValueConstraintValidator implements ConstraintValidator<ListValue, Integer> {

   private Set<Integer> set = new HashSet<>();

   /**
    * 初始化方法
    *
    * @param constraintAnnotation 约束注释
    */
   @Override
   public void initialize(ListValue constraintAnnotation) {
      int[] value = constraintAnnotation.value();
      for (int item : value) {
         set.add(item);
      }
      ConstraintValidator.super.initialize(constraintAnnotation);
   }

   /**
    * 是否校验成功
    *
    * @param value   字段提交校验的值
    * @param context 上下文
    * @return boolean
    */
   @Override
   public boolean isValid(Integer value, ConstraintValidatorContext context) {
      return set.contains(value);
   }
}
```
在bean上使用自定义校验规则和分组
`@ListValue(value{0,1},groups={interface.class})`

6.异常统一处理
```java
@Slf4j
@ResponseBody
@RestControllerAdvice(basePackages = "cn.xf.product.app")
public class MallExceptionAdvice {

    @ExceptionHandler(value = MethodArgumentNotValidException.class)
    public R handleValidException(MethodArgumentNotValidException e){
        log.error("数据校验异常，问题{},类型{}",e.getMessage(),e.getClass());
        BindingResult bindingResult = e.getBindingResult();
        Map<String, String> map = new HashMap<>();
        bindingResult.getFieldErrors().forEach((item)->{
           map.put(item.getField(),item.getDefaultMessage());
        });
        return R.error(CommonExceptionCode.VALID_EXCEPTION.getCode(), CommonExceptionCode.VALID_EXCEPTION.getMsg()).put("data",map);
    }

    @ExceptionHandler(value = Throwable.class)
    public R handleException(Exception e){
        return R.error(CommonExceptionCode.UNKNOWN_EXCEPTION.getCode(),CommonExceptionCode.UNKNOWN_EXCEPTION.getMsg());
    }
}
```

平台属性，属性分类CURD
1.父子组件值传递
子传父：点击节点后将数据传递给父组件-->通过节点单击事件
```
子组件通过点击事件后：
this.$emit("tree-node-click", data, node, component);
父组件引用的子组件中：
@tree-node-click="treenodeclick"
treenodeclick(data, node, component) {}
```

### 分页插件
```java
@Configuration
@MapperScan("com.baomidou.cloud.service.*.mapper*")
public class MybatisPlusConfig {
 
    @Bean
    public PaginationInterceptor paginationInterceptor() {
        PaginationInterceptor paginationInterceptor = new PaginationInterceptor();
        // 设置请求的页面大于最大页后操作， true调回到首页，false 继续请求  默认false
        // paginationInterceptor.setOverflow(false);
        // 设置最大单页限制数量，默认 500 条，-1 不受限制
        // paginationInterceptor.setLimit(500);
        // 开启 count 的 join 优化,只针对部分 left join
        paginationInterceptor.setCountSqlParser(new JsqlParserCountOptimize(true));
        return paginationInterceptor;
    }
}
```
以上并不能满足分页的实际要求，其中的总数total为0，需要加入PaginationInnerInterceptor
```java
public class MybatisPlusConfig {

   @Bean
   public MybatisPlusInterceptor paginationInnerInterceptor(){
      MybatisPlusInterceptor myBatisInterceptor = new MybatisPlusInterceptor();
      PaginationInnerInterceptor paginationInnerInterceptor = new PaginationInnerInterceptor();
      paginationInnerInterceptor.setOverflow(true);
      paginationInnerInterceptor.setDbType(DbType.MYSQL);
      myBatisInterceptor.addInnerInterceptor(paginationInnerInterceptor);
      return myBatisInterceptor;
   }
}
```

## Object分类

PO(persistant object):持久对象

DO(Domain Object):领域对象，抽取业务中的概念形成的对象

TO(Transfer Object):数据传输对象，服务与服务之间进行数据传输

DTO(Data Transfer Object):数据传输对象，

VO(Value Object):值对象，也称视图对象，用于封装传输来的数据

BO(Business Object):业务对象，封装多个PO

POJO（plain ordinary java object）:简单无规则对象

DAO（data access Object）：访问数据库


### FastDFS
原理：


### SPU与SKU
**SPU**：Standard Product Unit（标准化产品单元），是商品信息聚合的最小单位，是一组可复用、医检所的标准化信息的集合、描述了一个产品的特性

**SKU**：Stock Keeping Unit（库存量单位），库存进出计量的基本单位，对于大型连锁超时DC（配送中心）物流管理的一个必要方法，


### 规格参数和销售属性
每个分类下的商品共享规格参数、销售属性，只是有些商品不一定要用这个分类下的全部属性：
属性是以三级分类组织起来的
规格参数中有些是可以提供检索的
规格参数也是基本属性，他们具有自己的分组
属性的分组也是以三级分类组织起来的
属性名确定的，但是值是每个商品不同决定的


## Elasticsearch搜索模块

docker中安装elasticsearch

**导入依赖**
```maven
<dependency>
    <groupId>org.elasticsearch.client</groupId>
    <artifactId>elasticsearch-rest-high-level-client</artifactId>
    <version>7.4.2</version>
</dependency>
```

SpringBoot每个版本已经自定义了依赖的es版本,修改
```maven
<properties>
    <elasticsearch.version>7.4.2</elasticsearch.version>
</properties>
```

**添加配置类**
1.引入公共包common

2.添加配置文件
```properties
spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848

spring.application.name=elasticsearch
```

3.开启服务注册与发现
`@EnableDiscoveryClient`

4.配置类
```java
class ElasticSearchConfig{
   @Bean
   public RestHighLevelClient esClient(){
      return new RestHighLevelClient(
              RestClient.builder(
                      new HttpHost("192.168.56.10", 29200, "http")));
   }
}
```

5.测试

```
@RunWith(SpringJUnit4ClassRunner.class)
@SpringBootTest
class SearchApplicationTests {

    @Autowired
    private RestHighLevelClient client;

    @Test
    void contextLoads() {
        System.out.println(client);
    }

}
```

`java.lang.ClassNotFoundException: org.springframework.boot.context.properties.ConfigurationBeanFactoryMetadata`

解决：

```xml
<dependencyManagement>
     <dependencies>
         <dependency>
             <groupId>org.springframework.cloud</groupId>
             <artifactId>spring-cloud-dependencies</artifactId>
             <version>${spring-cloud.version}</version>
             <type>pom</type>
             <scope>import</scope>
         </dependency>
     </dependencies>
 </dependencyManagement>
```

此时需要忽略dataSource数据源

`@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)`


6.添加es的设置项
```java
// es添加安全访问规则后，都需要加上安全设置头

// 所以将该类型设置设置为一个单例

class ElasticSearchConfig{
   public static final RequestOptions COMMON_OPTIONS;
    static {
        RequestOptions.Builder builder = RequestOptions.DEFAULT.toBuilder();
        // builder.addHeader("Authorization", "Bearer " + TOKEN);
        // builder.setHttpAsyncResponseConsumerFactory(
        //         new HttpAsyncResponseConsumerFactory
        //                 .HeapBufferedResponseConsumerFactory(30 * 1024 * 1024 * 1024));
        COMMON_OPTIONS = builder.build();
    }
}
```

**测试保存数据**
```java
class SearchApplicationTests{
   
   @AutoWrite
   RestHighLevelClient client;
    
   @Test
   public void indexData() throws IOException {

      IndexRequest indexRequest = new IndexRequest("users");
      indexRequest.id("1");   //数据的id

      // indexRequest.source("userName","zhangsan","age",18,"gender","男");

      User user = new User();
      user.setUserName("zhangsan");
      user.setAge(18);
      user.setGender("男");

      String jsonString = JSON.toJSONString(user);
      indexRequest.source(jsonString, XContentType.JSON);  //要保存的内容

      // 执行保存操作
      IndexResponse index = client.index(indexRequest, ElasticSearchConfig.COMMON_OPTIONS);

      //提取有用的响应数据
      System.out.println(index);

   }
   @Data
   class User {
      private String userName;
      private String gender;
      private Integer age;
   }
}
```

**测试数据检索**



## es与项目结合

商品上架（SKU）后进行搜索，需要检索的信息尽量存储有用数据，

1.构建商品的映射
```
{
   "mapping":{
      "properties":{
         "skuId":{
            "type":"long"
         },
         "spuId":{
            "type":"keyword"
         },
         "skuTitle":{
            "type":"text",
            "analyzer":"ik_smart"
         },
         "skuPrice":{
            "type":"keyword",
            "index":false,
            "doc_values":false
         },
         "saleCount":{
            "type":"long"
         },
         "hasStock":{
            "type":"boolean"
         },
         "hotScore":{
            "type":"long"
         },
         "brandId":{
            "type":"long"
         },
         "catalogId":{
            "type":"long"
         },
         "brandName" : {
            "type" :"keyword",
            "index" : false,
            "doc_values": false
         },
         "brandImg" : {
            "type" : "keyword",
            "index" : false,
            "doc_values" : false
         },
         "catalogName" : {
            "type" : "keyword",
            "index" : false,
            "doc_values" : false
         },
         "attrs":{
            "type" : "nested",
            "properties" : {
               "attrId" : {
                  "type" : "long"
               },
               "attrName" : {
                  "type" : "keyword",
                  "index" : false,
                  "doc_values" : false
               },
               "attrValue" : {
                  "type" : "keyword"
               }
            }
         }
      }
   }
}
```


### 商品上架

<span style="color:green;font-weight:700">POST</span> `/product/spuInfo/{spuId}/up`

1.创建一个传输模型，从product到search，当前写在common中

```java
@Data
public class SkuEsModel {
    private Long skuId;
    private Long spuId;
    private String skuTitle;
    private BigDecimal skuPrice;
    private String skuImg;
    private Long saleCount;
    private Long hotScore;
    private Long brandId;
    private Long catalogId;
    private String brandName;
    private String brandImg;
    private String catalogName;
    // 商品规格属性
    private List<Attrs> attrs;

    @Data
    public static class Attrs {
        private Long attrId;
        private String attrName;
        private String attrValue;
    }
}
```

2、接口组装数据

```java
//1、查出当前spuId对应的所有sku信息,品牌的名字
        List<SkuInfoEntity> skuInfoEntities = skuInfoService.getSkusBySpuId(spuId);

        //TODO 4、查出当前sku的所有可以被用来检索的规格属性
        List<ProductAttrValueEntity> baseAttrs = productAttrValueService.baseAttrListforspu(spuId);

        List<Long> attrIds = baseAttrs.stream().map(attr -> {
            return attr.getAttrId();
        }).collect(Collectors.toList());

        List<Long> searchAttrIds = attrService.selectSearchAttrs(attrIds);
        //转换为Set集合
        Set<Long> idSet = searchAttrIds.stream().collect(Collectors.toSet());

        List<SkuEsModel.Attrs> attrsList = baseAttrs.stream().filter(item -> {
            return idSet.contains(item.getAttrId());
        }).map(item -> {
            SkuEsModel.Attrs attrs = new SkuEsModel.Attrs();
            BeanUtils.copyProperties(item, attrs);
            return attrs;
        }).collect(Collectors.toList());

        List<Long> skuIdList = skuInfoEntities.stream()
                .map(SkuInfoEntity::getSkuId)
                .collect(Collectors.toList());
        //TODO 1、发送远程调用，库存系统查询是否有库存
        Map<Long, Boolean> stockMap = null;
        try {
            R skuHasStock = wareFeignService.getSkuHasStock(skuIdList);
            //
            TypeReference<List<SkuHasStockVo>> typeReference = new TypeReference<List<SkuHasStockVo>>() {};
            stockMap = skuHasStock.getData(typeReference).stream()
                    .collect(Collectors.toMap(SkuHasStockVo::getSkuId, item -> item.getHasStock()));
        } catch (Exception e) {
            log.error("库存服务查询异常：原因{}",e);
        }

        //2、封装每个sku的信息
        Map<Long, Boolean> finalStockMap = stockMap;
        List<SkuEsModel> collect = skuInfoEntities.stream().map(sku -> {
            //组装需要的数据
            SkuEsModel esModel = new SkuEsModel();
            esModel.setSkuPrice(sku.getPrice());
            esModel.setSkuImg(sku.getSkuDefaultImg());

            //设置库存信息
            if (finalStockMap == null) {
                esModel.setHasStock(true);
            } else {
                esModel.setHasStock(finalStockMap.get(sku.getSkuId()));
            }

            //TODO 2、热度评分。0
            esModel.setHotScore(0L);

            //TODO 3、查询品牌和分类的名字信息
            BrandEntity brandEntity = brandService.getById(sku.getBrandId());
            esModel.setBrandName(brandEntity.getName());
            esModel.setBrandId(brandEntity.getBrandId());
            esModel.setBrandImg(brandEntity.getLogo());

            CategoryEntity categoryEntity = categoryService.getById(sku.getCatalogId());
            esModel.setCatalogId(categoryEntity.getCatId());
            esModel.setCatalogName(categoryEntity.getName());

            //设置检索属性
            esModel.setAttrs(attrsList);

            BeanUtils.copyProperties(sku,esModel);

            return esModel;
        }).collect(Collectors.toList());

        //TODO 5、将数据发给es进行保存：gulimall-search
        R r = searchFeignService.productStatusUp(collect);

        if (r.getCode() == 0) {
            //远程调用成功
            //TODO 6、修改当前spu的状态
            this.baseMapper.updaSpuStatus(spuId, ProductConstant.ProductStatusEnum.SPU_UP.getCode());
        } else {
            //远程调用失败
            //TODO 7、重复调用？接口幂等性:重试机制
        }
```

3、测试

添加当前服务端口12000

4、自定义的R中添加数据没有反序列化，无法添加，



### 整合thymeleaf

前端可直接使用，但是性能没有其他的高

``` maven
 <!-- 模板引擎 -->
 <dependency>
     <groupId>org.springframework.boot</groupId>
     <artifactId>spring-boot-starter-thymeleaf</artifactId>
 </dependency>
```

关闭缓存，在开发中能看到实时效果

```yml
spring:
	thymeleaf:
		cache: false
```

静态资源都放在static文件夹中；页面放在templates下，直接访问；查看**WebMvcAutoConfiguration**


SpringBoot在访问项目的时候，默认会找index.html

WebMVCAutoConfiguration 配置了默认的静态资源访问路径
`CLASSPATH_RESOURCE_LOCATIONS = { "classpath:/META-INF/resources/","classpath:/resources/", "classpath:/static/", "classpath:/public/" };`

**无法访问静态资源**
```java
@Configuration
public class WebMVCConfig extends WebMvcConfigurerAdapter {

    @Override
    public void addResourceHandlers(ResourceHandlerRegistry registry) {
        registry.addResourceHandler("/static/**").addResourceLocations("classpath:/static/");
    }
}
```

**页面实时更新**

引入devtools

**一级菜单**
```
@Override
    public List<CategoryEntity> queryLevelOneClassification() {
        System.out.println("queryLevelOneClassification start........");
        long l = System.currentTimeMillis();
        List<CategoryEntity> categoryEntities = this.baseMapper.selectList(
                new QueryWrapper<CategoryEntity>().eq("parent_cid", 0));
        System.out.println("消耗时间："+ (System.currentTimeMillis() - l));
        return categoryEntities;
    }
```

**二级菜单,三级菜单**

修改catalogLoader.js中json的请求，删除已有的json文件，编写请求json数据接口


### nginx搭建域名访问

正向代理与反向代理

```
正向代理：如科学上网，屏蔽客户端信息
反向代理：屏蔽内网服务器信息，负载均衡
```

**反向代理**

在本机hosts文件中配置 `ip地址  域名`

**nginx配置网关**
复制 /nginx/conf.d/.conf  /nginx/conf.d/mall.conf

```
server_name mall.com

localtion {
   proxy_pass http://192.168.56.1:9000
}
```
以上操作 为 本机配置dns ，指定域名指向虚拟机地址，虚拟机nginx配置代理访问本机服务

**配置负载均衡**

修改 nginx.conf 中配置上游服务器
`upstream mall{
   server 192.168.56.1
}`

修改 mall.conf
`
proxy_pass http://mall
`

本机网关中添加路由
`
- id: mall_host_route
  uri: lb://product
  #配置断言，什么路径下触发
  predicates:
    - Path=**.mall.com
  `

此时网关没有路由到请求路径，api却能访问，这是nginx问题

nginx在代理给网关时，会丢失host信息
--重新设置请求头  `proxy_set_header Host $host;`

!!!!!!!!!!!!!!!!!记得重启，重启不行就停止再启动


## 压力测试

通过压力测试，可以找到一些内存泄漏，并发与同步错误

**安装JMeter**



**性能指标**

1、响应时间（Response TIme）

2、HPS（Hits Per Second）：每秒点击次数，次/秒

3、TPS（Transaction per Second），系统每秒处理交易数量，笔/秒

4、QPS（Query per Second），系统每秒处理查询次数，次/秒

5、最大响应时间，指令发出到做出反应的时间

6、最少响应时间

7、90%响应时间



**JMeter**


## 堆内存和垃圾回收

### 内存模型

java源码编译为.class文件，jvm类装载器加载.class装载到jvm中，数据都存在运行时数据区（方法区，堆，程序计数器，虚拟机栈，本地方法栈），执行引擎依次调用栈中的方法，如果有本地方法（操作系统暴露的方法），程序的进度由程序计数器控制

### 堆

主要用来：对象实例创建，数组内存分配

堆分为：新生代，老年代



新创建的对象会先到新生代.Edge中，判断内存是否足够，不够执行Young GC（根据使用情况进行回收），将不怎么使用的对象放入幸存者区（Survival）中

如果内存依然不足，将长时间不使用的对象放入老年代中

若此时内存依然不够，执行Full GC，将老年代，新生代中的不用的数据全部清除

若内存不足，则OOM



### 内存监控

**Jconsole，Jvisualvm**

命令控制台`jconsole`或`jvisualvm`



### 现有中间键对性能的影响

当前系统又linux虚拟机nginx网关，后台网关中间件gateway

中间件越多，性能损失越大

业务：

```
db（MySql优化）
模板渲染速度（模板缓存）
静态资源
```

业务优化：关日志，优化数据库（加索引），开缓存

一个完整的请求包括返回数据和数据渲染



### Nginx动静分离

原来的动态请求和静态请求都发给nginx，在把请求发给网关

优化：

1、将所有静态资源放在nginx中（nginx/html/static）

2、配置规则，/static/**所有请求由nginx直接返回，这里配置的路径是nginx的容器内部路径

```
修改nginx配置：mall.conf
location /static/{
	root /usr/share/nginx/html;
}
location / {

}
```



### 调优

增大运行内存




## 缓存与分布式锁

### 缓存

即时性、数据一致性要求不高的（一致性：存储和读取的数据）；访问量大且更新频率不高的数据



### 分布式缓存

#### 本地模式在分布式下的问题

每个服务之间的数据不共享，每个服务需要单独发送请求获取数据，当一个服务修改了数据后，数据不同步



#### 共享缓存-中间件

整合redis

```
springboot中也整合了redis，引入pom

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
    <exclusions>
        <exclusion>
        <groupId>io.lettuce</groupId>
        <artifactId>lettuce-core</artifactId>
        </exclusion>
    </exclusions>
</dependency>

<dependency>
    <groupId>redis.clients</groupId>
    <artifactId>jedis</artifactId>
</dependency>

<!-- 以后使用Redisson作为所有分布式锁 -->
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.12.0</version>
</dependency>


配置redis
spring.redis.host: ip
spring.redis.password:
spring.redis.port: 6379

测试
@AutoWrite
StringRedisTemplate redis; // StringRedisTemplate是springboot自带的

@Test
public void test(){
	ValueOperations<String, String> ops = redis.opsForValue();
    //保存
    ops.set("hello","world_" + UUID.randomUUID().toString());
    //查询
    String hello = ops.get("hello");
    System.out.println("之前保存的数据:"+hello);
}
```



#### 改造三级分类

```java
public Map<String, List<Catelog2Vo>> getCatalogJson(){
    // 获取缓存中的数据
    String catalogJson = redisTemplate.opsForValue().get("catalogJson");
    if(StringUtils.isEmpty(catalogJson)){
        // 如果缓存中为空，查询数据库
        Map<String, List<Catelog2Vo>> jsonFromDb = getCatalogJsonFromDb();
        // 将查询出来的数据再放入缓存中
        String jsonString = JSON.toJSONString(jsonFromDb);
        redisTemplate.opsForValue().set("catalogJson",jsonString);
        return jsonFromDb;
    }
    // 将查出的数据转为指定对象
    Map<String, List<Catelog2Vo>> listMap = JSON.parseObject(
        catalogJson,
        new TypeReference<Map<String, List<Catelog2Vo>>>() {});
    return listMap;
}
```

#### 改造后造成OODF

压力测试导致对外内存异常（OutOfDirectMemeryError）

1、springboot2.0以后默认使用的lettuce作为操作redis的客户端，能使用netty进行网络通信

2、letture会出现让netty出现堆外内存溢出的bug，如果没有指定堆外内存，默认使用-Xmx300m

​		可以通过-Dio.netty.maxDirectMemory进行设置

但是不能使用-Dio.netty.maxDirectMemory调大堆外内存

解决方案：

1）升级lettuce客户端，2）切换使用jedis



**使用**

使用jedis

1、排除redis中默认引入的lettuce，避免让lettuce操作redis

2、引入jedis

```
<dependency>
    <groupId>redis.clients</groupId>
    <artifactId>jedis</artifactId>
</dependency>
```



### 高并发下缓存失效--缓存穿透

高并发下，`查询一个缓存与数据库都不存在的数据，但是每次请求都会查询，失去缓存意义`；当利用不存在的数据进行攻击，增大数据库瞬时压力，导致崩溃

解决：对空结果缓存

例如：二级三级菜单的查询







### 雪崩

`redis中的数据设置了相同的过期时间，导致在某一时刻同时失效，请求都到数据库，导致压力过重`



解决：原有失效时间基础上增加随机值，让过期时间不在同一时间发生

### 击穿

`热点数据在访问时失效，所有请求都到数据库`

解决：加锁，只让一个请求去查，其他人等待，查到以后释放锁，其他人获取锁后先查缓存

```
1.确定一把锁，就能锁住所有线程
2.得到锁后，再判断缓存中是否有数据，没有才继续查询
```

这样的本地锁，在分布式场景下依然存在问题

**在判断缓存中没有数据查询数据库后，需要立刻将数据存入数据库中**

本地锁不能锁住分布式情况，每个进程都会查询一次



### 分布式锁手动实现及问题

基本原理：所有进程向redis中占坑

```java
//1.redis中占坑，等价于redis中的NX（数据不存在时
Boolean status = redisTemplate.opsForValue().setIfAbsent(key,value);
//2.加锁成功...执行业务
if(status){
    // 执行业务
    
    // 业务执行成功，删除锁
    redisTemplate.delete(key);
}else{
    // 加锁失败...休眠100ms后自旋
}
```



场景一：业务执行异常或程序宕机，没有执行删除锁

```java
//1.redis中占坑
Boolean status = redisTemplate.opsForValue().setIfAbsent(key,value);// 等价于redis中的NX（数据不存在时）
//2.加锁成功...执行业务
//2.1.对锁添加过期时间
redisTemplate.expire(key,30,TimeUnit.SECONDS);
//2.2.业务执行成功，删除锁（setIfAbsent中的key值）
if(status)
    // 执行业务
    // 删除锁
	redisTemplate.delete(key);
//3.加锁失败...休眠100ms后自旋
```

场景二：准备设置过期时间，宕机

设置过期时间与加锁保持原子性

```java
//1.redis中占坑(过期时间与加锁同时进行)
Boolean status = redisTemplate.opsForValue().setIfAbsent(key,value,Time);// 等价于redis中的NX（数据不存在时）
//2.加锁成功...执行业务
//2.1.对锁添加过期时间
redisTemplate.expire(key,30,TimeUnit.SECONDS);
//2.2.业务执行成功，删除锁（setIfAbsent中的key值）
if(status)
    // 执行业务
    // 删除锁
	redisTemplate.delete(key);
//3.加锁失败...休眠100ms后自旋
```

场景三：锁过期，但其他线程持有锁，如何删除

```java
//1.redis中占坑(过期时间与加锁同时进行)
Boolean status = redisTemplate.opsForValue().setIfAbsent(key,uuid,Time);// 等价于redis中的NX（数据不存在时）
//2.加锁成功...执行业务
//2.1.对锁添加过期时间
redisTemplate.expire(key,30,TimeUnit.SECONDS);
//2.2.业务执行成功，删除锁（setIfAbsent中的key值）
if(status)
    // 执行业务
    // 判断当前redis是现在拿到的锁
    String localValue = redisTemplate.opsForValue().get(key);
	if(uuid.equals(localValue)){
        // 删除锁
		redisTemplate.delete(key);
    }
//3.加锁失败...休眠100ms后自旋
```

场景四：删除锁过程中，返回锁信息时过期，让其他线程获取锁并替换了当前获取到的锁信息

删除锁时也需要是原子操作（redis+lua脚本）

最终版：

```java
//1.redis中占坑(过期时间与加锁同时进行)
Boolean status = redisTemplate.opsForValue().setIfAbsent(key,uuid,Time);// 等价于redis中的NX（数据不存在时）
//2.加锁成功...执行业务
//2.1.对锁添加过期时间
redisTemplate.expire(key,30,TimeUnit.SECONDS);
//2.2.业务执行成功，删除锁（setIfAbsent中的key值）
if(status)
    try{
        // 执行业务
    }finally{
        // 脚本
    String script = "";
	redisTemplate.execute(new DefaultRedisScript<Integer>(script,Integer.class),Arrays.asList(key),uuid);
    }
//3.加锁失败...休眠100ms后自旋
```



### Redission整合分布式锁操作

分布式锁框架

1、依赖

```xml
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.12.0</version>
</dependency>
```

2、配置方法

https://github.com/redisson/redisson

程序化配置

```java
@Configuration
public class MyRedissonConfig {
    /**
     * 所有对Redisson的使用都是通过RedissonClient
     * @return
     * @throws IOException
     */
    @Bean(destroyMethod="shutdown")
    public RedissonClient redisson() throws IOException {
        //1、创建配置
        Config config = new Config();
        config.useSingleServer().setAddress("redis://192.168.56.10:6379");
        //2、根据Config创建出RedissonClient实例
        RedissonClient redissonClient = Redisson.create(config);
        return redissonClient;
    }
}
```

3、lock锁测试

`可重入锁：多个需要加锁的方法嵌套时，只要头部方法持有锁，后续方法就能直接使用`

/hello



优点：

```
锁的自动续期，如果业务超长，运行期间自动锁上新的30s。不用担心业务时间长，锁自动过期被删掉

加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认会在30s内自动过期，不会产生死锁问题

在执行lock()方法中，RedissonLock中的lock，一直尝试获取锁
```



#### lock看门狗

当对分布式锁设置了自动过期时间，且业务执行时间大于过期时间时，时间没有自动续期

```
如果我们传递了锁的超时时间，就发送给redis执行脚本，进行占锁，默认超时就是 我们制定的时间

如果我们未指定锁的超时时间，就使用 lockWatchdogTimeout = 30 * 1000 【看门狗默认时间】，只要占锁成功，就会启动一个定时任务【重新给锁设置过期时间，新的过期时间就是看门狗的默认时间】,每隔10秒都会自动的再次续期，续成30秒

续期时间internalLockLeaseTime 【看门狗时间】 / 3， 10s
```

但是依然推荐使用指定过期时间



#### 读写锁

要么只能读，要么只能写，保证一定能读到最新数据，修改期间，写锁是一个排他锁（互斥锁），读锁是共享锁

```
写锁没释放读锁必须等待
读 + 读 ：相当于无锁，并发读，只会在Redis中记录好，所有当前的读锁。他们都会同时加锁成功
写 + 读 ：必须等待写锁释放
写 + 写 ：阻塞方式
读 + 写 ：有读锁。写也需要等待
只要有读或者写的存都必须等待
```



#### 闭锁（CountDownLatch）

```java
@GetMapping(value = "/lockDoor")
    @ResponseBody
    public String lockDoor() throws InterruptedException {

        RCountDownLatch door = redisson.getCountDownLatch("door");
        door.trySetCount(5);
        // 当调用countDown()方法计数为0后及释放
        door.await();
        return "放假了...";
    }

    @GetMapping(value = "/gogogo/{id}")
    @ResponseBody
    public String gogogo(@PathVariable("id") Long id) {
        RCountDownLatch door = redisson.getCountDownLatch("door");
        door.countDown();       //计数-1
        return id + "班的人都走了...";
    }
```

#### 信号量



### 缓存一致性解决

1、双写

2、失效

两种模式都会导致缓存不一致的问题

```
1、如果是用户维度数据（订单数据，用户数据），这种并发几率小，不用考虑，缓存数据加上过期时间，每隔一段时间触发读的主动更新即可

2、如果是菜单，介绍等，可以使用canal订阅binlog方式

3、缓存数据+过期时间足够解决大部分业务对于缓存的要求

4、通过加锁保证并发读写，写写按顺序排队，读读没事
```



解决：canal



## SpringCache
1.整合依赖
    spring-boot-starter-cache、spring-boot-starter-data-redis
2.配置
    依赖自动配置了：CacheAutoConfiguration 会导入 RedisCacheConfiguration，自动配好了RedisCacheManager
    手动配置：1）声明使用redis使用缓存
3.使用
    @Cacheable：保存数据
    @CacheEvict：删除数据
    @CachePut：更新缓存
    @Caching：组合操作
    @CacheConfig：在类级别共享缓存

    开启缓存功能：@EnableCaching
    使用：@Cacheable(value = {"category"},key = "#root.method.name",sync = true)
    
    删除缓存
    使用：删除某个分区中所有缓存@CacheEvict(value="category",allEntries = true)
         删除某分区中多个缓存@Caching{
             @CacheEvict(value="category",key="'xxxx'")
             @CacheEvict(value="category",key="'xxxx'")
         }
```
每一个需要缓存的数据我们都来指定要放到那个名字的缓存。【缓存的分区(按照业务类型分)】
代表当前方法的结果需要缓存，如果缓存中有，方法都不用调用，如果缓存中没有，会调用方法。最后将方法的结果放入缓存
默认行为
     如果缓存中有，方法不再调用
     key是默认生成的:缓存的名字::SimpleKey::[](自动生成key值)
     缓存的value值，默认使用jdk序列化机制，将序列化的数据存到redis中
     默认时间是 -1：
  自定义操作：key的生成
     指定生成缓存的key：key属性指定，接收一个Spel
     指定缓存的数据的存活时间：配置文档中修改存活时间
     将数据保存为json格式
        自定义配置类，



```

3、Spring-Cache的不足之处：
 1）、读模式
     缓存穿透：查询一个null数据。解决方案：缓存空数据---开启换粗空数据
     缓存击穿：大量并发进来同时查询一个正好过期的数据。解决方案：加锁 ? 默认是无加锁的;使用sync = true来解决击穿问题
     缓存雪崩：大量的key同时过期。解决：加随机时间。加上过期时间
 2)、写模式：（缓存与数据库一致）
     1）、读写加锁。
     2）、引入Canal,感知到MySQL的更新去更新Redis
     3）、读多写多，直接去数据库查询就行
 总结：
     常规数据（读多写少，即时性，一致性要求不高的数据，完全可以使用Spring-Cache）：写模式(只要缓存的数据有过期时间就足够了)
     特殊数据：特殊设计

4.原理：
       CacheManager(RedisCacheManager)->Cache(RedisCache)->Cache负责缓存的读写



## 检索功能

1.引入模板引擎

2.配置域名转发

3.网关转发

4.封装搜索参数
    SearchParam

5.封装请求结果
    SearchController."/list.html"

6.检索逻辑

7.面包屑功能


## 异步，线程池

**初始化线程方法**
1.继承Thread类
2.实现Runnable接口
3.实现Callable接口
4.线程池

--ThreadTest.java--

Thread与Runnable启动线程不会得到异步后台返回值
Callable接口能得到后台返回结果

线程池优点：
    1.Thread类和Runnable接口没有返回值，Callable有返回值
    2.Thread类，Runnable接口，Callable接口不能控制返回的资源
    3.线程池可以控制资源，性能稳定


**线程池创建**
1.使用Executors工具类
2.原生创建线程池方法
```
ThreadPoolExecutor executor = new ThreadPoolExecutor(...)
```

线程池中参数：
    1.核心线程数，corePoolSize
    2.最大线程数：maximumPoolSize
    3.线程存活时间：KeepAliveTime，空闲线程的存活时间
    4.时间单位
    5.阻塞队列：用于核心线程以外其他线程等待
    6.线程工厂
    7.拒绝策略：超过最大线程数，且阻塞队列存满后其他线程的处理方式

线程池中执行顺序：
    1.创建线程池，准备核心线程数，准备接受任务
    2.当核心线程数存满后，将其他线程放入阻塞队列中，核心线程执行完当前线程，从阻塞队列中取出任务继续执行
    3.阻塞队列存满后，开启新线程，最大线程数量为max
    4.若max存满，其他线程则使用拒绝策略处理
    5.任务执行完毕，空闲线程在指定的存活时间后进行回收

## 异步执行

CompletableFuture

**基本使用**
```

```

**串行化**

## 详情页编写
item.html
功能实现：skuinfoserviceimpl.java
```
public SkuItemVo productInventoryDetails(Long skuId) throws Exception {
        SkuItemVo result = new SkuItemVo();
        // 1.商品库存基本信息
        SkuInfoEntity skuInfoEntity = getById(skuId);
        result.setInfo(skuInfoEntity);
        Long productId = skuInfoEntity.getSpuId();
        Long catalogId = skuInfoEntity.getCatalogId();

        // 2.商品库存图片信息
        List<SkuImagesEntity> productStockImages = skuImagesService.getProductStockImageInformationByProductStockId(skuId);
        result.setImages(productStockImages);

        // 3.商品信息的销售属性
        List<SkuItemSaleAttrVo> saleAttrValueList = skuSaleAttrValueService.queryAttrInfoByProductId(productId);
        result.setSaleAttr(saleAttrValueList);

        // 4.商品介绍
        SpuInfoDescEntity productDescribeInfo = spuInfoDescService.getById(productId);
        result.setDesc(productDescribeInfo);

        // 5.商品的规格参数信息
        List<SpuItemAttrGroupVo> attrGroupInfoList = attrGroupService.getProductSpecificationsByProductId(productId,catalogId);
        result.setGroupAttrs(attrGroupInfoList);

        return result;
    }
```

### 将详情页业务异步编排

1.添加线程池，添加线程配置类，使用自定以配置
product.MyThreadConfig
ThreadPoolConfigProperties

2.对业务进行编排
skuinfoserviceimpl

## 登录

创建认证模块，后续使用单点登录等

### 短信验证码整合

模拟验证码吧，服务商验证码没有发成功，就在后台模拟就好了

### 注册

流程：1、注册页面发送验证码到auth模块，auth收到后远程调用third模块发送验证码（本地获取验证码）

在获取验证码中，需要对业务设置防刷

2、获取验证码后校验后端数据格式

3、成功后注册，注册时查询数据库是否有重复数据，密码加密

密码加密：MD5(具有压缩性，容易计算，抗修改性，强抗碰撞)
        Spring提供的


### 登录

### 认证服务OAuth2

四大对象：Client（三方应用），Resource Owner（用户），Authorization Server（授权服务器），Resource Server（API）服务器

1.Client向Resource Owner申请请求认证
2.用户授权：输入账号密码
3.授权后进行认证
4.认证通过，返回访问令牌
5.使用访问令牌获取保护信息
6.认证令牌，返回受保护信息


### session共享

1.分布式中两个相同服务session不共享

session复制：但是网络传输有时间；
客户端存储：存在数据泄露问题；
hash一致性：只需要修改nginx配置；
统一存储：存入db或redis，没有安全隐患，但是增加了一次网络调用；
最终方案：统一存储+SpringSession

引入spring-session-data-redis
配置使用redis作为存储session容器：spring.session.store-type=redis
使用注解开启@EnableRedisHttpSession

想要跨子域session共享，对springsession进行配置

### SpringSession原理

@EnableRedisHttpSession中导入了RedisHttpSessionConfiguration配置
    1.给容器中添加了一个组件 RedisOperationSessionRepository
        Redis操作session，session的增删改查封装类
    2.SessionRepositoryFilter
        session的每个请求都要经过filter
        1）创建时，自动从容器中获取SessionRepository
        2）原始的request，response都被包装
        3）因为使用了装饰者模式，request被包装了，当使用request.getSession()时，实际调用的wrappedRequest.getSession
           而wrappedRequest.getSession最终是从SessionRepository中获取到的
    3.redis中数据的过期时间会自动续期

### 单点登录
xxl-sso 项目

原理

1.中央认证服务器

2.其他系统

3.只要一个登录了，其他都不用登录

4.全系统统一一个sessionId

## 购物车功能

1.需求
1）用户可在登录状态下将商品添加到购物车
    - 放入数据库
    - 放入redis
    - 放入mongodb
2）用户可在未登录状态下将商品添加到购物车
    - 放入localStorage
    - cookie
    - redis

2.数据（购物车中需要展示的数据）
    商品id、当前记录是否选中、商品标题、商品默认图片、单价、数量、总计价格、销售属性总额
    封装两个vo，一个是购物车，一个是购物车中商品项目

3.redis中如何保存
    1.使用list保存数据：如果想要修改商品属性或者删除，需要遍历数组才能获取到当前商品，效率不高
    2.使用hash：key为哪个用户的购物车，value为购物车中商品信息，也是一个hash结构，其中key为第几号商品，value为商品信息

4.实现
    1、引入jar包
    2、配置redis相关数据
    3、准备购物车的service--cartServiceImpl
    4、1）区分线上购物车与离线购物车---通过用户是否登录进行判断---引入springsession
       2）如果用户没登陆，购物车使用临时cookie保证离线购物车数据存在；用户中途登录后，依然使用临时cookie；第一次使用购物车时分配一个品是cookie

    5、通过 【拦截器组件】 实现判断用户是否登录--CartInterceptor.preHandle
        引入ThreadLocal，在前置拦截器执行时将数据存入，能够在当前业务中共享
    
    6.此时发现拦截器没有生效---拦截器需要执行对哪个方法进行拦截---MallWebConfig
    
    7.使用【后置拦截器】将cookie数据存入浏览器中

### 商品添加到购物车
    必要请求数据：商品id和商品数量
    
    1.判断当前是离线购物车还是线上购物车
    （使用线程池的方式异步编排方式获取以下信息）
    2.远程获取商品信息
    3.远程获取商品组合信息
    
    4.为了防止添加商品请求重复刷新导致的重复添加，使用重定向的方式处理

### 合并购物车--离线与线上
    点击【我的购物车】时
    1.判断用户是否登录
    2.用户登录了，获取当前用户离线时添加的商品，然后添加到在线购物车中，删除离线购物车中数据；再获取在线购物车拿到商品数据
    3.用户没有登录，获取离线购物车数据

### 商品选中与不选中--checkItem
### 商品数量修改--countItem
### 商品删除--deleteItem


## 消息队列

    【消息中间件】
    
    使用场景：异步处理；应用解耦；流量控制（流量削峰）
    
    概念：1.消息代理，代理我们发送消息
         2.目的地，消息发送到哪
    
    目的地形式：1.队列：点对点式（消息发送者将消息交给代理，代理将消息放入队列中等待消息接收者从队列中获取内容，读取到后将消息移除队列）
              2.主题：发布/订阅（消息发送者将消息交给代理，代理通过【发布/订阅】模式，所有订阅了的接收者都能收到消息）
    
    消息代理规范：1.JMS（java message service）java消息代理协议
                    ActiveMQ
               2.AMQP（advanced message queuing protocol）高级消息队列协议
                    RabbitMQ

### RabbitMQ

    由Erlang语言编写
    
    组件：
        1.生产者（publisher），消息提供者
        2.消息（message），会产生一个路由键，用于指定交换机绑定哪个消息队列
        3.交换器（exchange），负责接收消息
        4.消息队列（queue），消息存储未知
        5.绑定（bingding），交换机与消息队列绑定
        6.网络连接（connection），消费者与消息代理之间建立的连接
        7.信道（channel），通过信道传输数据
        8.消费者（customer）

### RabbitMQ运行机制

    消息生产者产生一个消息，消息发送给broker，broker将消息交给执行的交换机，交换机绑定多个队列，由交换机决定将消息路由给哪个消息队列（消息路由-由路由键决定），

### Exchange类型

    direct，fanout，topic，headers
    （直连，扇出，主题，headers）
    direct，headers：点对点通信
    fanout，topic：订阅发布模式
    
    direct：将消息交给执行队列，路由键按照绑定关系精确匹配
    fanout：广播类型，消息到达交换机后，绑定的队列都能收到消息，不区分路由键
    topic：发布订阅模式，将消息发送给部分绑定的队列，可使用通配符选取不同的队列


### 测试

    创建【my，my.news，my.emps，queue.news】消息队列
    
    1.创建【直连交换机】，在当前交换机中【publish message】指定队列发送消息，
        队列收到消息后，在队列中【get message】获取消息，获取模式有【Nack message requeue true】收到消息后重新入队
                                                          【Automatic ack】告诉交换机收到消息了，并且不重入交换机
                                                          【Reject requeue true】
                                                          【Reject requeue false】
    2.创建【广播交换机】，发送的消息所有队列都能收到
    3.创建【发布/订阅交换机】，绑定队列时，路由键需要模糊匹配，如【my.#】匹配一个或多个，【*.news】news前需要有前缀；一个队列可匹配多个路由键


### docker安装RabbitMQ

    docker run -d --name rabbitmq -p 5671:5671 -p 5672:5672 -p 4369:4369 -p 25672 -p 15671:15671 -p 15672:15672 rabbitmq:management
    
    4369,25672（Erlang发现&集群端口）
    5672，5671（AMQP端口）
    15672（web管理后台端口）账号密码都为guest
    61613，61614（STOMP协议端口）
    1883，8883（MQTT协议端口）
    
    自动重启命令
    docker update rabbitmq --restart=always

### springboot整合

    1.引入spring-boot-starter-amqp，【让RabbitAutoConfiguration自动配置生效】
        ---RabbitAutoConfiguration给容器中自动配置了【RabbitTemplate、AmqpAdmin、CachingConnectionFactory、RabbitMessageTemplate】
    2.配置，查看RabbitAutoConfiguration--rabbitConnectionFactoryBeanConfigurer可知，所有的配置文件都在【RabbitProperties】中，
        ---RabbitProperties读取的配置都是以spring.rabbitmq为前缀开头的属性
    3.开启RabbitMq
        ---@EnableRabbit
    
    4.测试
        注入AmqpAdmin
        --1、创建交换机
            amqpAdmin.declareExchange(new DirectExchange(交换机名字，持久模式，是否自动删除，其他此参数))
                                     (new FanoutExchange())
                                     (new CustomExchange())
                                     (new TopicExchange())
        --2、创建队列
            amqpAdmin.declareQueue(new Queue(队列名字，是否持久化，是否排他（只能一个使用者连接），是否自动删除，其他参数))
        --3、绑定队列和交换机
            amqpAdmin.declareBinding(new Binding(目的地（队列名），目的地类型，交换机（交换机名），路由键，其他参数))
    
        注入【RabbitTemplate】用于收发消息
        --4、发送消息
            rabbitTemplate.convertAndSend(交换机，路由键，消息)
    
            消息可以为对象，但是想要使用对象作为消息需要实现Serializable接口
    
            如果想传递Json数据
                --查看【RabbitTemplate】中，MessageConverter接口的子实现，【AbstractMessageConverter】中有【AbstractJackson2MessageConverter】
                    自定义配置--MyRabbitMqConfig
    
        --5、接收消息
            原理是监听队列，在业务中使用@RabbitListener【前提需要开启@EnableRabbit】，【监听的队列必须存在】
            方法参数可以存在以下的一个或多个
                --Message 接收消息的所有信息
                --T 返回数据请求体中的实际对象
                --Channel 当前传输数据的通道
    
            如果一个交换机被多个队列监听，每条消息只能有一个队列收到
    
            接收消息过程中，只有一条数据处理完后才会接收下一条消息
    
        --6、另一个注解RabbitHandler
            与RabbitListener注解一起使用，用于区分同一个队列中不同的消息
            RabbitListener用于监听队列
            RabbitHandler用于处理不同类型的消息
    
            虽然使用RabbitListener一个注解也能完成以上操作

### RabbitMQ消息确认机制--可靠抵达

    保证消息不丢失，可靠抵达，可以使用事务消息且效率不降低
    
    确认机制1；publish-->Exchange，ConfirmCallback：发送端确认，保证消息能到服务器
        --在创建【connectionFactory】的时候设置【PublisherConfirm（true）】选项，开启confirmcallback
        --消息只要被消息代理接收到，就会执行confirmcallback，如果是集群模式，应该被集群模式中所有代理接收到
        --被服务器接收到的消息只能表示消息到达了服务器，不能保证消息一定会被投递到目标队列
    
        开启功能：
            spring.rabbitmq.publisher-confirms=true
        设置确认回调
            MyRabbitMqConfig--initRabbitTemplate--setConfirmCallback


    确认机制2：Exchange-->Queue，returnCallback，消息正确抵达队列
        开启功能：
            spring.rabbitmq.publisher-returns=true
            # 只要消息抵达队列，以异步发送优先回调returnconfirm
            spring.rabbitmq.template.mandatory=true
        设置错误回调
            MyRabbitMqConfig--initRabbitTemplate--setReturnsCallback
    
    确认机制3：queue-->customer，ack机制，消费端确认
        保证消息被正确消费后，broker才能删除该消息
        --默认为自动确认，只要消息接收到，客户端能自动确认
            问题：
                处理第一个消息时：服务宕机，其他消息丢失
        --将回复模式修改为手动模式
            spring.rabbitmq.listener.simple.acknowledge-mode=manual
    
            此时只要没有手动确认收到的消息都不算接收到（状态为unacked），就算处理完后或服务器宕机也会回到队列中（状态为ready）
        --签收消息
            监听消息的方法中，有一个通道参数（channel），channel.basicAck(通道消息序号,是否批量签收模式)
                通道消息序号：Message.getMessageProperties().getDeliveryTag();
                是否批量签收：处理一个签收一个还是一起签收
        --拒绝消息
            // 通道消息序号，是否批量拒收，是否重新入队（入队后重新签收）
            channel.basicNack(long deliveryTag,boolean multiple,boolean requeue)
            channel.basicReject(long deliveryTag,boolean requeue)

### 使用Spring创建RabbitMq

    1.需要模块导入【spring-boot-starter-amqp】
    2.添加rabbitmq配置文件
    3.创建rabbitmq的配置类（交换机，队列，绑定关系）
    4.spring创建rabbitmq时是第一次连上rabbitmq时去创建，所以添加监听事件





## 订单模块

    1.引入redis（排除lettuce），将redis升级为jedis操作（引入依赖），整合session共享（引入springsession）
    
    2.订单
        电商系统涉及3个流，信息流（商品，优惠等），资金流（退款，付款），物流（发货，退货）。订单是将其整合起来
    
    3.订单构成
        用户信息：用户账号，收获地址，会员信息
        订单信息：订单类型，订单编号，父子订单，状态信息（订单，售后，物流），时间信息（创建，付款，发货，完成，关闭，收货）
        商品信息：店铺信息，商品属性，商品数量，价格信息
        物流信息：物流公司，配送方式，物流单号，物流状态
        支付信息：支付方式，流水单号，商品金额，运费，优惠券总额（促销活动，优惠券金额信息，虚拟币抵扣），实际支付
        促销信息：促销活动，优惠券信息，虚拟币抵扣
    
    4.订单状态
        待付款：用户提交订单，预下单，锁定库存并设置支付超时时间，超时后取消订单
        已付款/代发货：用户完成订单支付，需要记录支付时间，仓库系统进行进一步操作
        待收货：订单出库后，进入物流环节
        已完成：用户收到货后，订单完成交易
        已取消：待付款超时取消或用户自动取消
        售后中：订单完成后的其他服务
    
    5.订单拦截
        -- 跳转订单时前需要用户登录：【订单模块】创建【用户登录拦截器】和【web配置】
    
    6、订单确认页
        -- 封装需要返回数据
        -- 用户信息（收货人，收货地址等）
        -- 商品价格信息，商品库存信息
        -- 根据收获地址计算运费（没有对接三方接口，随便写写）
        -- 订单总价计算



完成使用spring创建rabbit队列等操作后继续

### 锁定库存

流程

```
订单下单时，无论是否成功，先将库存锁定
1.根据订单号和锁定的库存信息，保存一个库存工作单，用来回溯库存信息
2.查询该商品在那些仓库中存在
3.遍历仓库信息，开始尝试锁库存
4.锁定成功保存工单，将锁定消息发送给RabbitMq【延时队列】
5.RabbitMq监听延时队列
6.获取【库存延时队列】中的消息，查询数据库中是否真实存在
7.远程查询订单情况，如果没有订单，解锁库存；如果有订单，查看订单状态（订单取消的解锁库存，没取消不能解锁）
8.如果解锁过程中出现异常，拒绝接收消息，让消息回到队列中；没问题，接收消费消息
```

### 定时关单

订单创建成功，没有支付，取消订单

```
1.创建订单【延时队列】监听器--RabbitOrderReleaseListener
2.接收到消息后，尝试关闭订单
3.库存锁定成功后，将订单信息发送给RabbitMq【延时队列】
4.关闭订单前，需要再次确认订单状态
```



### 订单释放&库存解锁

如果出现订单创建成功，但是在发送给消息队列中出现卡顿，但是库存模块顺利完成，库存解锁时查询订单状态还是新建状态，这是库存解锁，消费消息。此时订单取消，库存无法释放

所以在订单释放时，也需要给交换机发送消息，告诉交换机订单释放。交换机将这样的订单与库存队列进行绑定，

```
仓库模块接收到订单释放消息后
1.根据订单号查询库存工作单，获取库存工作单id
2.根据库存工作单id，查询所有未解锁的库存进行解锁
3.对库存进行解锁
```

### 消息丢失，积压，重复问题

消息丢失：

```
1、消息发送出去，由于网络问题没有到达服务器
	失败后要有重试机制，可记录到数据库，采用定期扫描方案
	日志记录，将发送出的消息做好日志记录（将每个消息存入数据库）
	定期重发，从数据库中拿到数据进行重发
2、消息抵达服务器，要将消息写入磁盘才算成功，此时服务器宕机
	发送者添加回调机制
3、自动ack状态下，消费者收到消息，还没消费服务器宕机
	开始手动ACK，确认消费后移除，没消费重回队列
```



消息重复

```
1、消息消费成功，事务已提交，ack时，连接中断或宕机，消息从unack变为ready，让其他消费者消费
	将服务设置为幂等性
	使用防重表，每条消息都有唯一标识
2、消息消费失败，由于重试机制，消息又发送出去
```



消息积压

```
1、消费者宕机积压
2、消费者消费能力低
3、发送者流量太大
```



### 支付

沙箱环境测试

#### 加密-对称加密

发送方将铭文使用密钥A得到密文进行传输，接收方获取到密文后使用密钥A解密得到明文

#### 加密-非对称加密（RSA）

加密和解密密钥不一致

自己拿私钥，对方解密使用公钥

RSA工作流

商户发送消息，商户使用私钥对消息内容加签生成一个签名，将签名和消息内容一起通信；支付宝收到签名和消息内容后，使用公钥验证消息内容和签名是否一致；支付宝消费消息后，需要告诉商户是否成功；支付宝将支付成功的消息使用私钥进行签名（加签），将数据传输给商户，商户使用公钥验证消息内容和签名



#### 整合项目

```
1、导入依赖--支付宝SDK
2、添加了支付模板
3、添加配置常量
4、沙箱用户账号 cnhflm4974@sandbox.com

```



#### 支付完成

支付完成后跳转用户订单列表页

`http://member.mall.xyz/memberOrder.html`

查询当前登录用户所有订单列表

```
引入模板引擎，添加静态文件
添加会员网关
#### springsession配置和redis配置抽取出来（auth，cart，member，order，product，search）
引入redis，springsession用于登录信息共享
引入登录拦截器，添加mvcconfig
添加springsession配置，redis配置
开启springsession自动配置功能
```



### 收单

```
1.订单在支付页不支付，订单要过期了才支付，订单状态改为已支付，但是库存解锁了
	--使用支付宝自动收单，AlipayTemplate.timeout
2.订单解锁完成，正在解锁库存，异步通知才到
	--
```





## 订单幂等性

    幂等性：用户对同一操作发起一次请求和多次请求的结果是一致的
    
    解决方案：
        令牌机制
        数据库约束，使用唯一索引
        redis的set防重
    
    最终：使用令牌

## 订单事务
    此时订单创建失败会进行回滚，但是库存锁定失败订单依然能创建
    
    1.使用异常机制，失败后抛出异常，然后回滚
        -- 如果远程接口请求成功，但是返回超时，订单感知到，回滚
        -- 远程请求成功，但是后续方法异常，回滚，远程请求数据已被修改
    
        -- 此时@Transactional不再满足当前使用
            Transactional只能控制本地事务，控制不了其他服务事务
## 分布式事务

    本地事务：单体应用，一个服务连接一个数据库，不涉及到其他服务
    
    事务特性：ACID
    A（atomicity）原子性，操作不可分割，要么成功，要么失败
    C（Consistency）一致性，业务前后数据一致
    I（Isolation）隔离性
    D（Durabilily）持久性
    
    本事事务实现：
        在spring中，通过Transactional注解实现
    
    事务隔离级别：
        读未提交：一个事务能读取到其他未提交的数据，脏读
        读已提交：一个事务能读取到已提交的数据，
        重复读：一个事务读取多次数据都一致，即使有其他操作修改了（默认隔离级别）
        序列化
    
    事务传播行为：
        一个主事务中包含了多个子事务，子事务是否需要与主事务公用一个事务
    
        同一个对象内事务互调，即使设置了事务属性也失效，因为绕过了代理对象
        -- 解决：使用代理对象
            --1）引入spring-boot-starter-aop，使用其中的aspectj
            --2）@EnableAspectJAutoProxy（exposeProxy=true）：开启aspectj动态代理功能，以后所有动态代理都是aspectj创建
            --3）本类互调使用代理对象 当前类 对象 = AopContext.currentProxy();


        Propagation.REQUIRE：公用一个事务
        Propagation.REQUIRE_NEW：不共用
    
    分布式事务：
        在多服务之间互相调用时，最大的问题可能是通信中断异常
    
    CAP定理：
        一致性
        可用性
        分区容错性
    
    分布式一致性：
        协议：Raft
        节点状态：随从（Follower），候选【candidate】，领导（Leader）
        默认状态为随从
        如果当前节点没有收到领导给他发的信息，状态变为【候选】
            然后给其他节点发送一个投票，如果收到大多数节点的承认，称为【领导】
        客户端发送数据给【Leader】，先给自己赋值，但是未提交，然后发送请求给所有子节点，子节点收到请求进行设置值，然后反馈给【leader】节点，
        【leader】收到大多数节点的反馈后，将自己的数据提交（正式设置值），再给所有子节点发送可以提交命名
    
    分布式事务方案：
        2pc：首先事务协调器将需要同步的数据预发送给相关事务数据库，相关事务数据库反馈是否准备好，事务协调器收到消息后要求每个事务服务提交数据，
            如果有一个事务拒绝提交，就把所有事务数据库回滚到提交之前的状态
    
        tcc：3pc手动版
    
        柔性事务-最大努力通知：使用消息队列，按照规律进行通知，不保证数据一定通知成功，但会提供可查询数据的接口进行核对
    
        柔性事务-可靠消息+最终一致性方案


## Seata
    Alibaba提供的分布式事务解决框架
    
    每个模块都是一个RM（ResourceManagement），操作时都会向TC（TranstionManagement)事务管理器中注册自己模块，
    在执行过程中，如果有一个模块出现异常，TC就会通知其他模块一起回滚
    
    模式：
        AT模式：需要建立UNDO_LOG表
    
    修改配置文件：
        1.使用nacos作为注册中心
        2.引入依赖【spring-cloud-starter-alibaba-seata】，【seata-all】，seata-all的版本需要与steta服务版本一致
        3.在分布式事务上使用【@GlobalTransactional】注解
        4.使用到微服务分布式事务的都要使用【seata代理数据源】- 可自动/手动配置

## 延时队列--实现定时任务效果
    使用rabbitmq的TTl与死信Exchange结合
    TTL(Time To Live)：消息存活时间
    死信：消息被消费者拒收并且不会重入队列中；消息生命时间到达；消息队列满了，还有新的消息存入，丢弃最前面的消息
    死信Exchange：满足死信条件的消息不丢弃，放入其他的交换机中，该交换机将消息路由到指定消息队列中
    
    大致流程
        用户创建订单，将订单放入指定队列A中（死信队列），A队列中消息超时后，不丢弃消息，将消息放入B队列中
    
        商品库存









## 内网穿透

别人电脑，通过内网穿透服务商，然后找到我们电脑找到对应的网站

用户完成支付，支付宝在跳转的是本机地址，如果在外网访问可能导致无法回调

使用内网穿透

```
natapp
1、在通道中建立连接的地址和端口
2、启动本地穿透服务
3、修改nginx中地址
```



## 秒杀服务

流程

```
1.秒杀商品定时上架（当天上架第二天要秒杀的商品，减少数据库压力）
```

### 定时任务

#### cron表达式

语法：秒 分 时 日 月 周 年

#### Schedule

定时任务不能阻塞，默认是阻塞的

​		--可以让业务以异步运行的方式，提交到线程池

​		--定时任务支持任务线程池，设置TaskSchedulingProperties中属性，自动配置类：TaskSchedulingAutoConfiguration（偶尔异常，忽略）

​		--让定时任务异步执行，启用异步任务和标注异步任务@EnableAsync，@Async，自动配置类：TaskExecutionAutoConfiguration



所以最终使用【定时任务+异步任务】来保证定时任务不阻塞



## Sentinel





## 问题

1.测试类找不到service

`启动类与测试类的目录结构需要一致，不一致时在测试类中@SpringBootTest后加入启动类字节码文件`

2.数据库longblob类型java使用byte接收

3、测试时注入容器为空
`SpringBoot的测试需要加上@RunWith(SpringRunner.class)，指定Spring驱动进行测试`

4、使用测试注解时Error creating bean with name ‘configurationPropertiesBeans‘ defined in class path resource
```maven
nacos版本号引发的异常
    <!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-context -->
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-context</artifactId>
        <version>3.1.3</version>
    </dependency>

    <!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-commons -->
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-commons</artifactId>
        <version>3.1.3</version>
    </dependency>
```

5、rabbitTemplate循环依赖
    E:\File\Study\Note\Java\2022\pic\exception\屏幕截图 2022-10-14 092109.png

    解决：MyRabbitMqConfig--
    去掉@Autowried和@PostConstruct
    @Primary
    @Bean
    public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) {
        RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory);
        this.rabbitTemplate = rabbitTemplate;
        rabbitTemplate.setMessageConverter(messageConverter());
        initRabbitTemplate();
        return rabbitTemplate;
    }

6、feign远程调用丢失请求头信息
    浏览器发送请求时，第一次使用时请求头中自动携带cookie信息

    服务调用远程服务时，创建一个新的请求，此时请求头中什么都没有
    
    解决：添加Feign远程调用的请求拦截器，将第一次进来的request请求头进行保存，备以后续使用--MyFeignInterceptor

7、异步状态下feign远程调用请求头丢失
    在每个线程处理过程中将请求头放入
